#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Monday 
# 2021-02-22

## Thought for the Day
"Nobody knows everything. Everybody knows everything. And together, we can do anything!"
- Katy Salts

## Announcements
- Welcome back! Hope everybody is safe, operational, and stable!
- Starting Classification today!
- Lunch and Learn w/ Sean Oslin tomorrow. 


## Agenda
1. Welcome Back!
2. Stats Quiz
3. Introducing Classification ML!


## Notes 

Questions that Data Science Methods Can Answer

    Is this new observation A or B (or C, D, or E) (Classification)
    How Many or How Much of something (Regression)
    What groupings exist in the data already (Clustering)
    What should we expect to happen next? (Time Series Analysis)
    Is this weird? (Anomaly Detection)

Main Ideas

    With classification, we use labeled data to train algorithms to classify future data points.
    The training data allows us to train an algorithm to produce a decision rule
    Using a boundary between points or a distance between points, we classify new datapoints into A or B (or C or D or E)

Vocab

    Classifier: An algorithm that maps the input data to a specific category.

    Classification Model: A series of steps that takes the patterns of input variables, generalizes those patterns, and applies them to new data in order to predict the class.

    Feature: A feature, aka input/independent variable, is an individual measurable property of a phenomenon being observed.

    Binary Classification: Classification with two possible outcomes, e.g. pass/fail.

    Multiclass Classification: Classification with more than two classes, where each sample is assigned to one and only one target label, e.g. Grade levels of students in school (1st-12th).

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Tuesday
2/23/21
Thought for the day ->
“The challenge for anyone interested in making progress is to simultaneously have (1) the confidence to go after what you want and (2) the humility to accept who you are right now and (3) the willingness to build skills that bridge the gap between 1 and 2.”
-- James Clear
Agenda ->
1. Acquisition Exercises Work Time
2. Acquisition Exercises Walkthrough
3. Preparation Lesson
4. Preparation Exercise Work Time
Reminders ->
Sean’s Color LnL today at 1!


## Notes

steps to preparing data 

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#Wendsday
Thought for the Day:
"Some lessons you learn gradually and some you learn in a sudden moment, like a flash going off in a dark room" - John Darnielle, Wolf in White Van

Agenda 02-24-21:
1. Classification Prepare Exercise Review
2. Tidy Data Lesson
3. Half-day :)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#Thursday
02/25/2021
“By the time your perfect information has been gathered, the world has moved on.”  ― Phil Dourado
Agenda for today:
Exercise time for tidy-data
Walkthrough
Explore lesson

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#Friday
02/26/2021

#Notes
Common Evaluation Metrics

Now that we have introduced the idea of a confusion matrix, we can discuss some metrics that are derived from it.
Accuracy

# Accuracy is the number of times we predicted correctly divided by the total number of observations. Put another way:
TP + TNTP + TN + FP + FN

In our example above, this would be
3+23+2+1+2=58=0.625

So our model's overall accuracy is 62.5%.

Accuracy is a good, easy to understand metric, but can fail to capture the whole picture when the classes in the original dataset are not evenly distributed.

# Precision is the percentage of positive predictions that we made that are correct. Precision tells us how good our model's positive predictions are, and does not take into account false negatives or true negatives. More formally:
TPTP + FP

In our example:
33+1=0.75

That is, 75% of the time that we predicted someone likes coffee, we were right.

We might choose to optimize for precision when the cost of acting on a positive prediction is high. With precision as a metric, false negatives are "free", but false positives are costly. For example we might optimize for precision when predicting whether or not an email message is spam, as it is better to send a spam message to a user's inbox than it is to send a real message to the spam folder.

# 